{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from supportLibrary import *\n",
    "from IPython.display import display\n",
    "import ipywidgets as widgets\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Partition the Data\n",
    "\n",
    "To evaluate how good a Machine Learning model performs is called cross validation. To do this, you either split your data into a training set and a testing set (typically an 80:20 split) or you split your data into a training set, a validation set, and a testing set (typically 70:15:15). For the training/testing split, the model is trained with the training set, then its accuracy is evaluated using the testing set which the model has never seen before. For the training/validation/testing split, the model is trained with the testing set while periodically evaluating its accuracy on the validation set to make sure the model is not overfitting the testing data. Finally, the model is evaluated using the testing set which the model has never seen before. It is important to note that each partition contains random samples of the dataset to make sure the model is trained/tested with an even number of datapoints from each device.\n",
    "\n",
    "![title](Images/dataSplit.jpeg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('current4.csv')\n",
    "df = shuffleAndNormalize(df)\n",
    "trainX, trainY = getTrainingSet(df)\n",
    "testX, testY = getTestingSet(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose Which Model to Use\n",
    "\n",
    "### Deep Neural Net\n",
    "A model that, taking inspiration from the brain, is composed of layers consisting of simple connected units or neurons followed by nonlinearities.\n",
    "\n",
    "### Gradient Tree Boosting\n",
    "An ensemble learning method which involves sequentially adding new, shallow decision trees to a random forest model.\n",
    "\n",
    "### Random Forest\n",
    "An ensemble learning method that operates by constructing a multitude of decision trees at training time then outputting the class that is the mode of the classes output by the individual trees.\n",
    "\n",
    "### Support Vector Machine\n",
    "A classification algorithm that seeks to maximize the margin between positive and negative classes by mapping input data vectors to a higher dimensional space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "modelType = getModelType()\n",
    "display(modelType)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model\n",
    "\n",
    "The models we use for these types of machine learning problems assume that samples are independent. That is, no sample depends on values of a previous sample. To enforce this, we shuffle the samples to ensure that any sample is equally likely to follow any other sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = trainModel(modelType.value, trainX, trainY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantify the Model's Performance\n",
    "\n",
    "#### Accuracy\n",
    "Accuracy identifies the fraction of predictions that a classification model got right.\n",
    "$$\\text{Accuracy} = \\frac{\\text{Correct Predictions}}{\\text{Total Number of Examples}}$$\n",
    "\n",
    "#### Precision\n",
    "Precision identifies the frequency with which a model was correct when predicting the positive class. Loss in precision occurs when the model predicts a device needs maintenance when it actually does not.\n",
    "$$\\text{Precision} = \\frac{\\text{True Positives}}{\\text{True Positives + False Positives}}$$\n",
    "\n",
    "#### Recall\n",
    "Recall identifies out of the total number of positive examples in the dataset, how many the model correctly identified. Loss in recall occurs when the model predicts a device does not need maintenance when it actually does.\n",
    "$$\\text{Recall} = \\frac{\\text{True Positives}}{\\text{True Positives + False Negatives}}$$\n",
    "\n",
    "#### F1 Score\n",
    "F1 Score identifies the harmonic mean of the Precision and Recall in order to report an accurate average of the two metrics.\n",
    "$$\\text{F1 Score} = \\frac{2}{\\frac{1}{\\text{Precision}}+\\frac{1}{\\text{Recall}}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = getPredictions(model, testX, testY, modelType.value)\n",
    "accuracy, precision, recall, f1score = getAccuracyMetrics(testY, predictions)\n",
    "print(\"Accuracy {}\\nPrecision {}\\nRecall {}\\nf1 Score {}\".format(accuracy, precision, recall, f1score))\n",
    "plotConfusionMatrix(testY, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
